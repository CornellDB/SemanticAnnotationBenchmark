{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307f1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "from dotenv import dotenv_values\n",
    "from langchain import PromptTemplate, LLMChain, OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from tqdm import tqdm\n",
    "from evaluate import load\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env file with API KEY using full path\n",
    "config = dotenv_values(\"../.env\")\n",
    "os.environ['OPENAI_API_KEY'] = config[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f5b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_text = {\n",
    "    \"I dont'know\": \"I dont'know\",\n",
    "    \"addressLocality\": \"locality of address\",\n",
    "    \"postalCode\": \"postal code\",\n",
    "    \"addressRegion\": \"region of address\",\n",
    "    \"Country\": \"country\",\n",
    "    \"priceRange\": \"price range\",\n",
    "    \"Hotel/name\": \"name of hotel\",\n",
    "    \"telephone\": \"telephone\",\n",
    "    \"faxNumber\": \"fax number\",\n",
    "    \"Date\": \"date\",\n",
    "    \"Restaurant/name\": \"name of restaurant\",\n",
    "    \"paymentAccepted\": \"payment accepted\",\n",
    "    \"DayOfWeek\": \"day of week\",\n",
    "    \"Review\": \"review\",\n",
    "    \"Organization\": \"organization\",\n",
    "    \"DateTime\": \"date and time\",\n",
    "    \"MusicAlbum/name\": \"name of music album\",\n",
    "    \"MusicArtistAT\": \"music artist\",\n",
    "    \"MusicRecording/name\": \"name of music recording\",\n",
    "    \"Photograph\": \"photograph\",\n",
    "    \"CoordinateAT\": \"coordinate\",\n",
    "    \"Event/name\": \"name of event\",\n",
    "    \"EventAttendanceModeEnumeration\": \"event attendance mode\",\n",
    "    \"EventStatusType\": \"event status\",\n",
    "    \"currency\": \"currency\",\n",
    "    \"email\": \"email\",\n",
    "    \"Time\": \"time\",\n",
    "    \"LocationFeatureSpecification\": \"location feature\",\n",
    "    \"Duration\": \"duration\",\n",
    "    \"Event/description\": \"description of event\",\n",
    "    \"Restaurant/description\": \"description of restaurant\",\n",
    "    \"Rating\": \"rating\",\n",
    "    \"Hotel/description\": \"description of hotel\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f6e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to map ChatGPT answers to label set: synonyms can be added here\n",
    "text_to_label = {\n",
    "    \"locality of address\": \"addressLocality\",\n",
    "    \"postal code\": \"postalCode\",\n",
    "    \"region of address\": \"addressRegion\",\n",
    "    \"country\": \"Country\",\n",
    "    \"price range\": \"priceRange\",\n",
    "    \"name of hotel\": \"Hotel/name\",\n",
    "    \"telephone\": \"telephone\",\n",
    "    \"fax number\": \"faxNumber\",\n",
    "    \"date\": \"Date\",\n",
    "    \"name of restaurant\": \"Restaurant/name\",\n",
    "    \"payment accepted\": \"paymentAccepted\",\n",
    "    \"day of week\": \"DayOfWeek\",\n",
    "    \"review\": \"Review\",\n",
    "    \"organization\": \"Organization\",\n",
    "    \"date and time\": \"DateTime\",\n",
    "    \"music artist\": \"MusicArtistAT\",\n",
    "    \"music album\": \"MusicAlbum/name\",\n",
    "    \"name of music recording\": \"MusicRecording/name\",\n",
    "    \"photograph\": \"Photograph\",\n",
    "    \"coordinate\": \"CoordinateAT\",\n",
    "    \"name of event\": \"Event/name\",\n",
    "    \"event attendance mode\": \"EventAttendanceModeEnumeration\",\n",
    "    \"event status\": \"EventStatusType\",\n",
    "    \"currency\": \"currency\",\n",
    "    \"email\": \"email\",\n",
    "    \"time\": \"Time\",\n",
    "    \"location feature\": \"LocationFeatureSpecification\",\n",
    "    \"duration\": \"Duration\",\n",
    "    \"description of event\": \"Event/description\",\n",
    "    \"description of restaurant\": \"Restaurant/description\",\n",
    "    \"description of hotel\": \"Hotel/description\",\n",
    "    \"rating\": \"Rating\",\n",
    "    #Added\n",
    "    \"description of restaurants\": \"Restaurant/description\",\n",
    "    \"name of music artist\": \"MusicArtistAT\",\n",
    "    \"description of hotel amenities\": \"LocationFeatureSpecification\",\n",
    "    \"amenities\": \"LocationFeatureSpecification\",\n",
    "    \"name of album\": \"MusicAlbum/name\",\n",
    "    \"i don't know\": \"-\",\n",
    "    \"name of music album\": \"MusicAlbum/name\",\n",
    "    \"music recording\": \"MusicRecording/name\",\n",
    "    \"event name\": \"Event/name\",\n",
    "    \"description of hotels\": \"Hotel/description\",\n",
    "    \"name of hotels\": \"Hotel/name\",\n",
    "    \"duration of music recording or video\": \"Duration\",\n",
    "    \"name of organization\": \"Organization\",\n",
    "    \"hotel amenities\": \"LocationFeatureSpecification\",\n",
    "    \"amenities of hotel room\": \"LocationFeatureSpecification\",\n",
    "    \"check-in time\": \"Time\",\n",
    "    \"check-out time\": \"Time\",\n",
    "    \"time of check-in\": \"Time\",\n",
    "    \"time of check-out\": \"Time\",\n",
    "    \"hotel features\": \"LocationFeatureSpecification\",\n",
    "    \"name of aparthotel\": \"Hotel/name\",\n",
    "    \"event description\": \"Event/description\",\n",
    "    \"email address\": \"email\",\n",
    "    \"room amenities\": \"LocationFeatureSpecification\",\n",
    "    \"end date\": \"Date\",\n",
    "    \"descriptions of events\": \"Event/description\",\n",
    "    \"mode of attendance\": \"EventAttendanceModeEnumeration\",\n",
    "    \"name of song\": \"MusicRecording/name\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b93f4d",
   "metadata": {},
   "source": [
    "## Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cd0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/cta-test-table-wise.pkl', \"rb\") as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "examples = [example[1] for example in test]\n",
    "labels = [l for example in test for l in example[2]]\n",
    "topics = [example[3] for example in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5235a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(examples))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33eeece",
   "metadata": {},
   "source": [
    "## Choose prompt template: without or with instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efc5cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper name: table\n",
    "original_template = \"\"\"\n",
    "\n",
    "Answer the question based on the task below. If the question cannot be answered using the information provided answer with \"I don't know\".\n",
    "\n",
    "Task: Classify the columns of a given table with only one of the following classes that are separated with comma: description of event, description of restaurant, locality of address, postal code, region of address, country, price range, telephone, date, name of restaurant, payment accepted, day of week, review, organization, date and time, coordinate, name of event, event attendance mode, event status, currency, time, description of hotel, name of hotel, location feature, rating, fax number, email, photograph, name of music recording, music artist, name of album, duration.\n",
    "\n",
    "Table: {input}\n",
    "\n",
    "Class:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Paper name: table + instructions\n",
    "original_inst_template = \"\"\"\n",
    "\n",
    "Answer the question based on the task and instructions below. If the question cannot be answered using the information provided answer with \"I don't know\".\n",
    "\n",
    "Task: Classify the columns of a given table with only one of the following classes that are separated with comma: description of event, description of restaurant, locality of address, postal code, region of address, country, price range, telephone, date, name of restaurant, payment accepted, day of week, review, organization, date and time, coordinate, name of event, event attendance mode, event status, currency, time, description of hotel, name of hotel, location feature, rating, fax number, email, photograph, name of music recording, music artist, name of album, duration.\n",
    "\n",
    "Instructions: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. For each column, select a class that best represents the meaning of all cells in the column. 4. Answer with the selected class for each columns with the format Column1: class.\n",
    "\n",
    "Table:\n",
    "{input}\n",
    "\n",
    "Class:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4590de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified original\n",
    "modified_original_template = \"\"\"\n",
    "\n",
    "Answer the question based on the task below. If the question cannot be answered using the information provided answer with \"I don't know\".\n",
    "\n",
    "Task: Classify the columns of a given table with only one of the following classes that are separated with comma: description of event, description of restaurant, locality of address, postal code, region of address, country, price range, telephone, date, name of restaurant, payment accepted, day of week, review, organization, date and time, coordinate, name of event, event attendance mode, event status, currency, time, description of hotel, name of hotel, location feature, rating, fax number, email, photograph, name of music recording, music artist, name of album, duration. Answer with the semantic concept for each column with the format Column1: semantic concept.\n",
    "\n",
    "Table: {input}\n",
    "\n",
    "Class:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d704f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New prompt\n",
    "semantic_concept_template = \"\"\"\n",
    "\n",
    "Answer the question based on the task below. If the question cannot be answered using the information provided answer with \"I don't know\".\n",
    "\n",
    "Task: Suggest a semantic concept for each column of a given table. Answer with the semantic concept for each column with the format Column1: semantic concept.\n",
    "\n",
    "Table: {input}\n",
    "\n",
    "Semantic concepts:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc61f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper name: table + instructions\n",
    "inst_template = \"\"\"\n",
    "\n",
    "Answer the question based on the task and instructions below. If the question cannot be answered using the information provided answer with \"I don't know\".\n",
    "\n",
    "Task: Suggest a semantic concept for each column of a given table.\n",
    "\n",
    "Instructions: 1. Look at the input given to you and make a table out of it. 2. Look at the cell values in detail. 3. For each column, suggest a semantic concept that best represents the meaning of all cells in the column. 4. Answer with the semantic concept for each column with the format Column1: semantic concept.\n",
    "\n",
    "Table:\n",
    "{input}\n",
    "\n",
    "Semantic concepts:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69280f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt to ask gpt to classify labels \n",
    "classify_label_template = \"\"\"\n",
    "\n",
    "Task: Classify the semantic concept {input} with only one of the following classes that are separated with comma: description of event, description of restaurant, locality of address, postal code, region of address, country, price range, telephone, date, name of restaurant, payment accepted, day of week, review, organization, date and time, coordinate, name of event, event attendance mode, event status, currency, time, description of hotel, name of hotel, location feature, rating, fax number, email, photograph, name of music recording, music artist, name of album, duration.\n",
    "\n",
    "Class:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9cc367",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_template = \"\"\"\n",
    "\n",
    "Answer the question based on the task below. If the question cannot be answered using the information provided answer with \"I don't know\".\n",
    "\n",
    "Task: Suggest a semantic concept for each column of a given table. Answer with the semantic concept for each column with the format Column1: semantic concept.\n",
    "\n",
    "Table: {input}\n",
    "\n",
    "Semantic concepts:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "debug_template_top_5 = \"\"\"\n",
    "\n",
    "Answer the question based on the task below. If the question cannot be answered using the information provided answer with \"I don't know\".\n",
    "\n",
    "Task: Suggest 5 possible semantic concept for each column of a given table. Answer with the semantic concept for each column with the format Column1: possible semantic concept 1, possible semantic concept 2, possible semantic concept 3, possible semantic concept 4, possible semantic concept 5. \n",
    "\n",
    "Table: {input}\n",
    "\n",
    "Semantic concepts:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "debug_template_album = \"\"\"\n",
    "\n",
    "Could this column be about music albums?\n",
    "\n",
    "Table: {input}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "check_template = \"\"\"\n",
    "\n",
    "Critique whether these semantic concepts matches their respective columns in the given table and improve on them. If there is no further improvements to be made, just say 'It's good'.\n",
    "\n",
    "Semantic concepts: {prev_output}\n",
    "\n",
    "Table: {input}\n",
    "\n",
    "Answer with the semantic concept for each column with the format Column1: semantic concept. \n",
    "\n",
    "Semantic concepts:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "check_template_best_of_5 = \"\"\"\n",
    "\n",
    "Critique whether these semantic concepts matches their respective columns in the given table and improve on them. Choose the best semantic concept for each column.\n",
    "\n",
    "Semantic concepts: {prev_output}\n",
    "\n",
    "Table: {input}\n",
    "\n",
    "Answer with the semantic concept for each column with the format Column1: semantic concept. \n",
    "\n",
    "Semantic concepts:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19177971",
   "metadata": {},
   "source": [
    "## Load LLM and run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9940af79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpt_3_turbo = ChatOpenAI(model_name='gpt-3.5-turbo-0301', temperature=0)\n",
    "gpt_4 = ChatOpenAI(model_name='gpt-4-0613', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca67e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_type = \"modified_original_template\"\n",
    "if prompt_type == \"original_template\":\n",
    "    prompt = PromptTemplate(template=original_template, input_variables=['input'])\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=gpt_3_turbo)\n",
    "    llm_chain_4 = LLMChain(prompt=prompt, llm=gpt_4)\n",
    "elif prompt_type == \"modified_original_template\":\n",
    "    prompt = PromptTemplate(template=modified_original_template, input_variables=['input'])\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=gpt_3_turbo)\n",
    "    llm_chain_4 = LLMChain(prompt=prompt, llm=gpt_4)\n",
    "elif prompt_type == \"semantic_concept\":\n",
    "    prompt = PromptTemplate(template=semantic_concept_template, input_variables=['input'])\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=gpt_3_turbo)\n",
    "    llm_chain_4 = LLMChain(prompt=prompt, llm=gpt_4)\n",
    "elif prompt_type == \"with_inst\":\n",
    "    prompt = PromptTemplate(template=inst_template, input_variables=['input'])\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=gpt_3_turbo)\n",
    "    llm_chain_4 = LLMChain(prompt=prompt, llm=gpt_4)\n",
    "elif prompt_type == \"debug_template\":\n",
    "    prompt = PromptTemplate(template=debug_template, input_variables=['input'])\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=gpt_3_turbo)\n",
    "    llm_chain_4 = LLMChain(prompt=prompt, llm=gpt_4)\n",
    "elif prompt_type == \"debug_template_top_5\":\n",
    "    prompt = PromptTemplate(template=debug_template_top_5, input_variables=['input'])\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=gpt_3_turbo)\n",
    "    llm_chain_4 = LLMChain(prompt=prompt, llm=gpt_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82446d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "improve_prompt = PromptTemplate(template=check_template_best_of_5, input_variables=['input', 'prev_output'])\n",
    "llm_chain_improve = LLMChain(prompt=improve_prompt, llm=gpt_3_turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f083a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_column_major(example: str) -> str:\n",
    "    lines = example.split(\"\\n\")\n",
    "    col_major = [col + \": \" for col in lines[0].split(\"||\")]\n",
    "    for line in lines[1:]:\n",
    "        for i, val in enumerate(line.split(\"||\")):\n",
    "            col_major[i] += val + \", \"\n",
    "    debug_eg = \"\\n\".join(col_major[:-1])\n",
    "    return debug_eg\n",
    "\n",
    "print(convert_to_column_major(examples[40]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preds(preds: list[str], file_name: str):\n",
    "    #Save predictions in a file:\n",
    "    with open(file_name,'wb') as f:\n",
    "        pickle.dump(preds,f)\n",
    "\n",
    "def load_preds(file_name: str):\n",
    "    #Save predictions in a file:\n",
    "    with open(file_name,'rb') as f:\n",
    "        preds = pickle.load(f)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e985602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zero-shot prediction\n",
    "preds_gpt35 = [llm_chain.run({'input': example}) for example in examples]\n",
    "save_preds(preds_gpt35, \"predictions/gpt35-prompt-table-without-instructions-og-modified.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d64ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zero-shot prediction\n",
    "preds_gpt35 = [llm_chain.run({'input': convert_to_column_major(example)}) for example in examples]\n",
    "save_preds(preds_gpt35, \"predictions/gpt35-prompt-table-without-instructions-col-major.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feaa26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_gpt4 = [llm_chain_4.run({'input': example}) for example in examples]\n",
    "save_preds(preds_gpt4, \"predictions/gpt4-prompt-table-with-instructions.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab6cab8",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003621b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = load(\"bertscore\")\n",
    "preds = preds_gpt35 # OR load from one of the pickle files previously saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_new(preds, bert_threshold=0.85):\n",
    "    ids, predictions, original_preds, parsed_preds, top_5_predictions, highest_bertscores = [], [], [], [], [], []\n",
    "    i=0\n",
    "    for j, table_preds in enumerate(tqdm(preds)):\n",
    "        # How many columns does the table have? : To control cases when less/more classes are returned\n",
    "        table_number = len(test[j][2])\n",
    "        \n",
    "        if \"Semantic concepts:\" in table_preds:\n",
    "            table_preds = table_preds.split(\"Class:\")[1]\n",
    "        \n",
    "        #Break predictions into either \\n or ,\n",
    "        if \":\" in table_preds or \"-\" in table_preds:\n",
    "            if \":\" in table_preds:\n",
    "                separator = \":\"\n",
    "                start = 1\n",
    "                end = table_number+1\n",
    "            else:\n",
    "                separator = \"-\"  \n",
    "                start = 1\n",
    "                end = table_number+1\n",
    "        else:\n",
    "            separator = \",\"\n",
    "            start = 0\n",
    "            end = table_number\n",
    "            \n",
    "        col_preds = table_preds.split(separator)[start:end]\n",
    "        for pred in col_preds:\n",
    "            i+=1\n",
    "            \n",
    "            # Remove break lines\n",
    "            if \"\\n\" in pred:\n",
    "                pred = pred.split('\\n')[0].strip()\n",
    "            # Remove commas\n",
    "            if \",\" in pred:\n",
    "                pred = pred.split(\",\")[0].strip()\n",
    "            # Remove paranthesis\n",
    "            if '(' in pred:\n",
    "                pred = pred.split(\"(\")[0].strip()\n",
    "            #Remove points\n",
    "            if '.' in pred:\n",
    "                pred = pred.split(\".\")[0].strip()\n",
    "            # Lower-case prediction\n",
    "            pred = pred.strip().lower()\n",
    "            parsed_preds.append(pred)\n",
    "            original_preds.append(table_preds)\n",
    "            ids.append(j)\n",
    "\n",
    "            classes = list(text_to_label.keys())\n",
    "            bertscores = np.array(bertscore.compute(predictions=[pred] * len(classes), references=classes, lang=\"en\")[\"f1\"])\n",
    "            index = np.argsort(bertscores)[-5:]\n",
    "            max_index = index[-1]\n",
    "            top_5_predictions.append([text_to_label[classes[i]] for i in index])\n",
    "            highest_bertscores.append(bertscores[index])\n",
    "\n",
    "            highest_score = bertscores[max_index]\n",
    "\n",
    "            if highest_score > bert_threshold:\n",
    "                predictions.append(text_to_label[classes[max_index]])\n",
    "            else:\n",
    "                print(f\"For test example {i} out of label space prediction: {pred}\")\n",
    "                predictions.append('-')\n",
    "            \n",
    "        # If more/less predictions for table\n",
    "        if len(col_preds) < table_number:\n",
    "            for m in range(0, table_number-len(col_preds)):\n",
    "                original_preds.append(table_preds)\n",
    "                ids.append(j)\n",
    "                predictions.append(\"-\")\n",
    "                parsed_preds.append(\"-\")\n",
    "                top_5_predictions.append([])\n",
    "                highest_bertscores.append(0)\n",
    "                i+=1\n",
    "    return ids, predictions, original_preds, parsed_preds, highest_bertscores, top_5_predictions\n",
    "\n",
    "ids, class_predictions, original_preds, parsed_preds, highest_bertscores, top_5_preds = evaluation_new(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b3db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ids), len(class_predictions), len(original_preds), len(highest_bertscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c91b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"prompt_output_id\": ids, \n",
    "                   \"label\": labels, \n",
    "                   \"original_pred\": original_preds, \n",
    "                   \"parsed_col_pred\": parsed_preds, \n",
    "                   \"class_pred_using_bert\": class_predictions, \n",
    "                   \"highest_bertscore\": highest_bertscores,\n",
    "                   \"top_5_preds\": top_5_preds})\n",
    "df.to_csv(\"predictions/preds_gpt35_with_inst_og_modified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26702dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map predictions to label space\n",
    "def evaluation_old(preds):\n",
    "    # Map predictions to label space\n",
    "    predictions = []\n",
    "    i=0\n",
    "    for j, table_preds in enumerate(preds):\n",
    "        # How many columns does the table have? : To control cases when less/more classes are returned\n",
    "        table_number = len(test[j][2])\n",
    "        \n",
    "        if \"Class:\" in table_preds:\n",
    "            table_preds = table_preds.split(\"Class:\")[1]\n",
    "        \n",
    "        #Break predictions into either \\n or ,\n",
    "        if \":\" in table_preds or \"-\" in table_preds:\n",
    "            if \":\" in table_preds:\n",
    "                separator = \":\"\n",
    "                start = 1\n",
    "                end = table_number+1\n",
    "            else:\n",
    "                separator = \"-\"  \n",
    "                start = 1\n",
    "                end = table_number+1\n",
    "        else:\n",
    "            separator = \",\"\n",
    "            start = 0\n",
    "            end = table_number\n",
    "            \n",
    "        col_preds = table_preds.split(separator)[start:end]\n",
    "        \n",
    "        for pred in col_preds:\n",
    "            i+=1\n",
    "            \n",
    "            # Remove break lines\n",
    "            if \"\\n\" in pred:\n",
    "                pred = pred.split('\\n')[0].strip()\n",
    "            # Remove commas\n",
    "            if \",\" in pred:\n",
    "                pred = pred.split(\",\")[0].strip()\n",
    "            # Remove paranthesis\n",
    "            if '(' in pred:\n",
    "                pred = pred.split(\"(\")[0].strip()\n",
    "            #Remove points\n",
    "            if '.' in pred:\n",
    "                pred = pred.split(\".\")[0].strip()\n",
    "            # Lower-case prediction\n",
    "            pred = pred.strip().lower()\n",
    "            \n",
    "            if pred in text_to_label:\n",
    "                predictions.append(text_to_label[pred])\n",
    "            else:\n",
    "                print(f\"For test example {i} out of label space prediction: {pred}\")\n",
    "                predictions.append('-')\n",
    "            \n",
    "        # If more/less predictions for table\n",
    "        if len(col_preds) < table_number:\n",
    "            for m in range(0, table_number-len(col_preds)):\n",
    "                predictions.append('-')\n",
    "                i+=1\n",
    "    return predictions\n",
    "\n",
    "old_preds = evaluation_old(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14a5709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could potentially use GPT to match open world label to classification label?\n",
    "prompt_classify = PromptTemplate(template=classify_label_template, input_variables=['input'])\n",
    "llm_chain_c = LLMChain(prompt=prompt_classify, llm=gpt_3_turbo)\n",
    "llm_chain_4_c = LLMChain(prompt=prompt_classify, llm=gpt_4)\n",
    "llm_chain_c.run({'input': \"state\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab2350d",
   "metadata": {},
   "source": [
    "### Calculate Precision, Recall, Macro-F1 and Micro-F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81907f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"predictions/preds_gpt35_without_inst_og_modified.csv\",index_col=0)\n",
    "labels, preds = df[\"label\"], df[\"class_pred_using_bert\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80edaecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(len(df[df[\"label\"] == df[\"class_pred_using_bert\"]]))\n",
    "df['label_in_top_5'] = df[['label','top_5_preds']].apply(\n",
    "    lambda row: row['label'] in row['top_5_preds'], axis=1\n",
    ")\n",
    "print(len(df[df[\"label_in_top_5\"] == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a1bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_scores(y_tests, y_preds, num_classes):\n",
    "    types = list(set(labels))\n",
    "    types = types + [\"-\"]\n",
    "    \n",
    "    y_tests = [types.index(y) for y in y_tests]\n",
    "    y_preds = [types.index(y) for y in y_preds]\n",
    "    \n",
    "    #Confusion matrix\n",
    "    cm = np.zeros(shape=(num_classes,num_classes))\n",
    "    \n",
    "    for i in range(len(y_tests)):\n",
    "        cm[y_preds[i]][y_tests[i]] += 1\n",
    "        \n",
    "    report = {}\n",
    "    \n",
    "    for j in range(len(cm[0])):\n",
    "        report[j] = {}\n",
    "        report[j]['FN'] = 0\n",
    "        report[j]['FP'] = 0\n",
    "        report[j]['TP'] = cm[j][j]\n",
    "\n",
    "        for i in range(len(cm)):\n",
    "            if i != j:\n",
    "                report[j]['FN'] += cm[i][j]\n",
    "        for k in range(len(cm[0])):\n",
    "            if k != j:\n",
    "                report[j]['FP'] += cm[j][k]\n",
    "\n",
    "        precision = report[j]['TP'] / (report[j]['TP'] + report[j]['FP'])\n",
    "        recall = report[j]['TP'] / (report[j]['TP'] + report[j]['FN'])\n",
    "        f1 = 2*precision*recall / (precision + recall)\n",
    "        \n",
    "        if np.isnan(f1):\n",
    "            f1 = 0\n",
    "        if np.isnan(precision):\n",
    "            f1 = 0\n",
    "        if np.isnan(recall):\n",
    "            f1 = 0\n",
    "\n",
    "        report[j]['p'] =  precision\n",
    "        report[j]['r'] =  recall\n",
    "        report[j]['f1'] = f1\n",
    "    \n",
    "    all_fn = 0\n",
    "    all_tp = 0\n",
    "    all_fp = 0\n",
    "\n",
    "    for r in report:\n",
    "        if r != num_classes-1:\n",
    "            all_fn += report[r]['FN']\n",
    "            all_tp += report[r]['TP']\n",
    "            all_fp += report[r]['FP']\n",
    "        \n",
    "    class_f1s = [ report[class_]['f1'] for class_ in report]\n",
    "    class_p = [ 0 if np.isnan(report[class_]['p']) else report[class_]['p'] for class_ in report]\n",
    "    class_r = [ 0 if np.isnan(report[class_]['r']) else report[class_]['r'] for class_ in report]\n",
    "    macro_f1 = sum(class_f1s[:-1]) / (num_classes-1)\n",
    "    \n",
    "    p =  sum(class_p[:-1]) / (num_classes-1)\n",
    "    r =  sum(class_r[:-1]) / (num_classes-1)\n",
    "    micro_f1 = all_tp / ( all_tp + (1/2 * (all_fp + all_fn) )) \n",
    "    \n",
    "    per_class_eval = {}\n",
    "    for index, t in enumerate(types[:-1]):\n",
    "        per_class_eval[t] = {\"Precision\":class_p[index], \"Recall\": class_r[index], \"F1\": class_f1s[index]}\n",
    "    \n",
    "    evaluation = {\n",
    "        \"Micro-F1\": micro_f1,\n",
    "        \"Macro-F1\": macro_f1,\n",
    "        \"Precision\": p,\n",
    "        \"Recall\": r\n",
    "    }\n",
    "    \n",
    "    return evaluation, per_class_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1770b52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation, per_class_eval = calculate_f1_scores(labels, preds, 33)\n",
    "print(evaluation)\n",
    "print(per_class_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd645fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(labels, preds, average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4ba678",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a8a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"predictions/preds_gpt35_without_inst.csv\",index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d8fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = df[df[\"lionel_annot\"] != df[\"label\"]]\n",
    "error_df[\"table\"] = error_df.apply(lambda row: examples[row[\"prompt_output_id\"]], axis=1)\n",
    "error_df[\"all_labels\"] = error_df.apply(lambda row: test[row[\"prompt_output_id\"]][2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca33b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df.reset_index(inplace=True, drop=True)\n",
    "error_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f492f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(error_df)):\n",
    "    print(\"=\"*10)\n",
    "    print(f\"Table {error_df.loc[idx, 'prompt_output_id']}\")\n",
    "    print(error_df.loc[idx,\"table\"])\n",
    "    print(error_df.loc[idx,\"all_labels\"])\n",
    "    \n",
    "    print(f\"Ground truth: {error_df.loc[idx,'label']}\")\n",
    "    print(f\"Raw output: {error_df.loc[idx,'parsed_col_pred']}\")\n",
    "    print(f\"Annot: {error_df.loc[idx,'lionel_annot']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
